{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6260b8d4",
   "metadata": {},
   "source": [
    "### Agentic  RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5a3b7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "649f248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"HF_TOKEN\"] = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accd8ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39ae57c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BOSS\\Desktop\\langGraph\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "hugging_embedding = HuggingFaceEmbeddings(\n",
    "    model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a2ab77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/overview/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content=\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\nOur new LangChain Academy Course Deep Research with LangGraph is now live! Enroll for free.\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Overview\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      What is an agent?\\n    \\n\\n\\n\\n\\n\\n      Key features\\n    \\n\\n\\n\\n\\n\\n      High-level building blocks\\n    \\n\\n\\n\\n\\n\\n      Package ecosystem\\n    \\n\\n\\n\\n\\n\\n      Visualize an agent graph\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph APIs\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph APIs\\n          \\n\\n\\n\\n\\n    Graph API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runtime\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Core capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Core capabilities\\n          \\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Durable execution\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tracing\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Additional resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      What is an agent?\\n    \\n\\n\\n\\n\\n\\n      Key features\\n    \\n\\n\\n\\n\\n\\n      High-level building blocks\\n    \\n\\n\\n\\n\\n\\n      Package ecosystem\\n    \\n\\n\\n\\n\\n\\n      Visualize an agent graph\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nagent\\n\\n\\n\\n\\nAgent development using prebuilt components¶\\nLangGraph provides both low-level primitives and high-level prebuilt components for building agent-based applications. This section focuses on the prebuilt, ready-to-use components designed to help you construct agentic systems quickly and reliably—without the need to implement orchestration, memory, or human feedback handling from scratch.\\nWhat is an agent?¶\\nAn agent consists of three components: a large language model (LLM), a set of tools it can use, and a prompt that provides instructions.\\nThe LLM operates in a loop. In each iteration, it selects a tool to invoke, provides input, receives the result (an observation), and uses that observation to inform the next action. The loop continues until a stopping condition is met — typically when the agent has gathered enough information to respond to the user.\\n\\n\\nAgent loop: the LLM selects tools and uses their outputs to fulfill a user request.\\n\\nKey features¶\\nLangGraph includes several capabilities essential for building robust, production-ready agentic systems:\\n\\nMemory integration: Native support for short-term (session-based) and long-term (persistent across sessions) memory, enabling stateful behaviors in chatbots and assistants.\\nHuman-in-the-loop control: Execution can pause indefinitely to await human feedback—unlike websocket-based solutions limited to real-time interaction. This enables asynchronous approval, correction, or intervention at any point in the workflow.\\nStreaming support: Real-time streaming of agent state, model tokens, tool outputs, or combined streams.\\nDeployment tooling: Includes infrastructure-free deployment tools. LangGraph Platform supports testing, debugging, and deployment.\\nStudio: A visual IDE for inspecting and debugging workflows.\\nSupports multiple deployment options for production.\\n\\nHigh-level building blocks¶\\nLangGraph comes with a set of prebuilt components that implement common agent behaviors and workflows. These abstractions are built on top of the LangGraph framework, offering a faster path to production while remaining flexible for advanced customization.\\nUsing LangGraph for agent development allows you to focus on your application's logic and behavior, instead of building and maintaining the supporting infrastructure for state, memory, and human feedback.\\nPackage ecosystem¶\\nThe high-level components are organized into several packages, each with a specific focus.\\n\\n\\n\\nPackage\\nDescription\\nInstallation\\n\\n\\n\\n\\nlanggraph-prebuilt (part of langgraph)\\nPrebuilt components to create agents\\npip install -U langgraph langchain\\n\\n\\nlanggraph-supervisor\\nTools for building supervisor agents\\npip install -U langgraph-supervisor\\n\\n\\nlanggraph-swarm\\nTools for building a swarm multi-agent system\\npip install -U langgraph-swarm\\n\\n\\nlangchain-mcp-adapters\\nInterfaces to MCP servers for tool and resource integration\\npip install -U langchain-mcp-adapters\\n\\n\\nlangmem\\nAgent memory management: short-term and long-term\\npip install -U langmem\\n\\n\\nagentevals\\nUtilities to evaluate agent performance\\npip install -U agentevals\\n\\n\\n\\nVisualize an agent graph¶\\nUse the following tool to visualize the graph generated by\\ncreate_react_agent\\nand to view an outline of the corresponding code.\\nIt allows you to explore the infrastructure of the agent as defined by the presence of:\\n\\ntools: A list of tools (functions, APIs, or other callable objects) that the agent can use to perform tasks.\\npre_model_hook: A function that is called before the model is invoked. It can be used to condense messages or perform other preprocessing tasks.\\npost_model_hook: A function that is called after the model is invoked. It can be used to implement guardrails, human-in-the-loop flows, or other postprocessing tasks.\\nresponse_format: A data structure used to constrain the type of the final output, e.g., a pydantic BaseModel.\\n\\n\\n\\n\\nFeatures\\n tools\\n pre_model_hook\\n post_model_hook\\n response_format\\n\\n\\n\\nGraph\\n\\n\\n\\nThe following code snippet shows how to create the above agent (and underlying graph) with\\ncreate_react_agent:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Guides\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Run an agent\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")],\n",
       " [Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/run_agents/', 'title': 'Run an agent', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRun an agent\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\nOur new LangChain Academy Course Deep Research with LangGraph is now live! Enroll for free.\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Run an agent\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Basic usage\\n    \\n\\n\\n\\n\\n\\n      Inputs and outputs\\n    \\n\\n\\n\\n\\n\\n      Input format\\n    \\n\\n\\n\\n\\n\\n      Output format\\n    \\n\\n\\n\\n\\n\\n      Streaming output\\n    \\n\\n\\n\\n\\n\\n      Max iterations\\n    \\n\\n\\n\\n\\n\\n      Additional Resources\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph APIs\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph APIs\\n          \\n\\n\\n\\n\\n    Graph API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runtime\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Core capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Core capabilities\\n          \\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Durable execution\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tracing\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Additional resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Basic usage\\n    \\n\\n\\n\\n\\n\\n      Inputs and outputs\\n    \\n\\n\\n\\n\\n\\n      Input format\\n    \\n\\n\\n\\n\\n\\n      Output format\\n    \\n\\n\\n\\n\\n\\n      Streaming output\\n    \\n\\n\\n\\n\\n\\n      Max iterations\\n    \\n\\n\\n\\n\\n\\n      Additional Resources\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nagent\\n\\n\\n\\n\\nRunning agents¶\\nAgents support both synchronous and asynchronous execution using either .invoke() / await .ainvoke() for full responses, or .stream() / .astream() for incremental streaming output. This section explains how to provide input, interpret output, enable streaming, and control execution limits.\\nBasic usage¶\\nAgents can be executed in two primary modes:\\n\\nSynchronous using .invoke() or .stream()\\nAsynchronous using await .ainvoke() or async for with .astream()\\n\\nSync invocationAsync invocation\\n\\n\\nfrom langgraph.prebuilt import create_react_agent\\n\\nagent = create_react_agent(...)\\n\\nresponse = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]})\\n\\n\\n\\nfrom langgraph.prebuilt import create_react_agent\\n\\nagent = create_react_agent(...)\\nresponse = await agent.ainvoke({\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]})\\n\\n\\n\\n\\nInputs and outputs¶\\nAgents use a language model that expects a list of messages as an input. Therefore, agent inputs and outputs are stored as a list of messages under the messages key in the agent state.\\nInput format¶\\nAgent input must be a dictionary with a messages key. Supported formats are:\\n\\n\\n\\nFormat\\nExample\\n\\n\\n\\n\\nString\\n{\"messages\": \"Hello\"} — Interpreted as a HumanMessage\\n\\n\\nMessage dictionary\\n{\"messages\": {\"role\": \"user\", \"content\": \"Hello\"}}\\n\\n\\nList of messages\\n{\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]}\\n\\n\\nWith custom state\\n{\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}], \"user_name\": \"Alice\"} — If using a custom state_schema\\n\\n\\n\\nMessages are automatically converted into LangChain\\'s internal message format. You can read\\nmore about LangChain messages in the LangChain documentation.\\n\\nUsing custom agent state\\nYou can provide additional fields defined in your agent\\'s state schema directly in the input dictionary. This allows dynamic behavior based on runtime data or prior tool outputs.\\nSee the context guide for full details.\\n\\n\\nNote\\nA string input for messages is converted to a HumanMessage. This behavior differs from the prompt parameter in create_react_agent, which is interpreted as a SystemMessage when passed as a string.\\n\\nOutput format¶\\nAgent output is a dictionary containing:\\n\\nmessages: A list of all messages exchanged during execution (user input, assistant replies, tool invocations).\\nOptionally, structured_response if structured output is configured.\\nIf using a custom state_schema, additional keys corresponding to your defined fields may also be present in the output. These can hold updated state values from tool execution or prompt logic.\\n\\nSee the context guide for more details on working with custom state schemas and accessing context.\\nStreaming output¶\\nAgents support streaming responses for more responsive applications. This includes:\\n\\nProgress updates after each step\\nLLM tokens as they\\'re generated\\nCustom tool messages during execution\\n\\nStreaming is available in both sync and async modes:\\nSync streamingAsync streaming\\n\\n\\nfor chunk in agent.stream(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\\n    stream_mode=\"updates\"\\n):\\n    print(chunk)\\n\\n\\n\\nasync for chunk in agent.astream(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\\n    stream_mode=\"updates\"\\n):\\n    print(chunk)\\n\\n\\n\\n\\n\\nTip\\nFor full details, see the streaming guide.\\n\\nMax iterations¶\\nTo control agent execution and avoid infinite loops, set a recursion limit. This defines the maximum number of steps the agent can take before raising a GraphRecursionError. You can configure recursion_limit at runtime or when defining agent via .with_config():\\nRuntime.with_config()\\n\\n\\nfrom langgraph.errors import GraphRecursionError\\nfrom langgraph.prebuilt import create_react_agent\\n\\nmax_iterations = 3\\nrecursion_limit = 2 * max_iterations + 1\\nagent = create_react_agent(\\n    model=\"anthropic:claude-3-5-haiku-latest\",\\n    tools=[get_weather]\\n)\\n\\ntry:\\n    response = agent.invoke(\\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what\\'s the weather in sf\"}]},\\n        {\"recursion_limit\": recursion_limit},\\n    )\\nexcept GraphRecursionError:\\n    print(\"Agent stopped due to max iterations.\")\\n\\n\\n\\nfrom langgraph.errors import GraphRecursionError\\nfrom langgraph.prebuilt import create_react_agent\\n\\nmax_iterations = 3\\nrecursion_limit = 2 * max_iterations + 1\\nagent = create_react_agent(\\n    model=\"anthropic:claude-3-5-haiku-latest\",\\n    tools=[get_weather]\\n)\\nagent_with_recursion_limit = agent.with_config(recursion_limit=recursion_limit)\\n\\ntry:\\n    response = agent_with_recursion_limit.invoke(\\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what\\'s the weather in sf\"}]},\\n    )\\nexcept GraphRecursionError:\\n    print(\"Agent stopped due to max iterations.\")\\n\\n\\n\\n\\nAdditional Resources¶\\n\\nAsync programming in LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Overview\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Overview\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')],\n",
       " [Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content=\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\nOur new LangChain Academy Course Deep Research with LangGraph is now live! Enroll for free.\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Overview\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph APIs\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph APIs\\n          \\n\\n\\n\\n\\n    Graph API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runtime\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Core capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Core capabilities\\n          \\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Durable execution\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n            Human-in-the-loop\\n          \\n\\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Key capabilities\\n    \\n\\n\\n\\n\\n\\n      Patterns\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n    Add human intervention\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tracing\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Additional resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Key capabilities\\n    \\n\\n\\n\\n\\n\\n      Patterns\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nhil\\nhuman-in-the-loop\\noverview\\n\\n\\n\\n\\nHuman-in-the-loop¶\\nTo review, edit, and approve tool calls in an agent or workflow, use LangGraph's human-in-the-loop features to enable human intervention at any point in a workflow. This is especially useful in large language model (LLM)-driven applications where model output may require validation, correction, or additional context.\\n\\n\\n\\n\\nTip\\nFor information on how to use human-in-the-loop, see Enable human intervention and Human-in-the-loop using Server API.\\n\\nKey capabilities¶\\n\\n\\nPersistent execution state: Interrupts use LangGraph's persistence layer, which saves the graph state, to indefinitely pause graph execution until you resume. This is possible because LangGraph checkpoints the graph state after each step, which allows the system to persist execution context and later resume the workflow, continuing from where it left off. This supports asynchronous human review or input without time constraints.\\nThere are two ways to pause a graph:\\n\\nDynamic interrupts: Use interrupt to pause a graph from inside a specific node, based on the current state of the graph.\\nStatic interrupts: Use interrupt_before and interrupt_after to pause the graph at pre-defined points, either before or after a node executes.\\n\\n\\n\\nAn example graph consisting of 3 sequential steps with a breakpoint before step_3.  \\n\\n\\nFlexible integration points: Human-in-the-loop logic can be introduced at any point in the workflow. This allows targeted human involvement, such as approving API calls, correcting outputs, or guiding conversations.\\n\\n\\nPatterns¶\\nThere are four typical design patterns that you can implement using interrupt and Command:\\n\\nApprove or reject: Pause the graph before a critical step, such as an API call, to review and approve the action. If the action is rejected, you can prevent the graph from executing the step, and potentially take an alternative action. This pattern often involves routing the graph based on the human's input.\\nEdit graph state: Pause the graph to review and edit the graph state. This is useful for correcting mistakes or updating the state with additional information. This pattern often involves updating the state with the human's input.\\nReview tool calls: Pause the graph to review and edit tool calls requested by the LLM before tool execution.\\nValidate human input: Pause the graph to validate human input before proceeding with the next step.\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Call tools\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Add human intervention\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls  = [\n",
    "    \"https://langchain-ai.github.io/langgraph/agents/overview/\",\n",
    "    \"https://langchain-ai.github.io/langgraph/agents/run_agents/\",\n",
    "    \"https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/\"\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75a81310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/overview/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='Overview\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\nOur new LangChain Academy Course Deep Research with LangGraph is now live! Enroll for free.\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Overview\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n    Overview'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/overview/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='Agent development\\n          \\n\\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      What is an agent?\\n    \\n\\n\\n\\n\\n\\n      Key features\\n    \\n\\n\\n\\n\\n\\n      High-level building blocks\\n    \\n\\n\\n\\n\\n\\n      Package ecosystem\\n    \\n\\n\\n\\n\\n\\n      Visualize an agent graph\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph APIs\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph APIs\\n          \\n\\n\\n\\n\\n    Graph API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runtime\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Core capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Core capabilities\\n          \\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Durable execution\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tracing\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/overview/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='MCP\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tracing\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Additional resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      What is an agent?\\n    \\n\\n\\n\\n\\n\\n      Key features\\n    \\n\\n\\n\\n\\n\\n      High-level building blocks\\n    \\n\\n\\n\\n\\n\\n      Package ecosystem\\n    \\n\\n\\n\\n\\n\\n      Visualize an agent graph\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nagent'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/overview/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='Package ecosystem\\n    \\n\\n\\n\\n\\n\\n      Visualize an agent graph\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nagent\\n\\n\\n\\n\\nAgent development using prebuilt components¶\\nLangGraph provides both low-level primitives and high-level prebuilt components for building agent-based applications. This section focuses on the prebuilt, ready-to-use components designed to help you construct agentic systems quickly and reliably—without the need to implement orchestration, memory, or human feedback handling from scratch.\\nWhat is an agent?¶\\nAn agent consists of three components: a large language model (LLM), a set of tools it can use, and a prompt that provides instructions.\\nThe LLM operates in a loop. In each iteration, it selects a tool to invoke, provides input, receives the result (an observation), and uses that observation to inform the next action. The loop continues until a stopping condition is met — typically when the agent has gathered enough information to respond to the user.'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/overview/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='Agent loop: the LLM selects tools and uses their outputs to fulfill a user request.\\n\\nKey features¶\\nLangGraph includes several capabilities essential for building robust, production-ready agentic systems:\\n\\nMemory integration: Native support for short-term (session-based) and long-term (persistent across sessions) memory, enabling stateful behaviors in chatbots and assistants.\\nHuman-in-the-loop control: Execution can pause indefinitely to await human feedback—unlike websocket-based solutions limited to real-time interaction. This enables asynchronous approval, correction, or intervention at any point in the workflow.\\nStreaming support: Real-time streaming of agent state, model tokens, tool outputs, or combined streams.\\nDeployment tooling: Includes infrastructure-free deployment tools. LangGraph Platform supports testing, debugging, and deployment.\\nStudio: A visual IDE for inspecting and debugging workflows.\\nSupports multiple deployment options for production.'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/overview/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content=\"High-level building blocks¶\\nLangGraph comes with a set of prebuilt components that implement common agent behaviors and workflows. These abstractions are built on top of the LangGraph framework, offering a faster path to production while remaining flexible for advanced customization.\\nUsing LangGraph for agent development allows you to focus on your application's logic and behavior, instead of building and maintaining the supporting infrastructure for state, memory, and human feedback.\\nPackage ecosystem¶\\nThe high-level components are organized into several packages, each with a specific focus.\\n\\n\\n\\nPackage\\nDescription\\nInstallation\\n\\n\\n\\n\\nlanggraph-prebuilt (part of langgraph)\\nPrebuilt components to create agents\\npip install -U langgraph langchain\\n\\n\\nlanggraph-supervisor\\nTools for building supervisor agents\\npip install -U langgraph-supervisor\\n\\n\\nlanggraph-swarm\\nTools for building a swarm multi-agent system\\npip install -U langgraph-swarm\"),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/overview/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='langgraph-swarm\\nTools for building a swarm multi-agent system\\npip install -U langgraph-swarm\\n\\n\\nlangchain-mcp-adapters\\nInterfaces to MCP servers for tool and resource integration\\npip install -U langchain-mcp-adapters\\n\\n\\nlangmem\\nAgent memory management: short-term and long-term\\npip install -U langmem\\n\\n\\nagentevals\\nUtilities to evaluate agent performance\\npip install -U agentevals\\n\\n\\n\\nVisualize an agent graph¶\\nUse the following tool to visualize the graph generated by\\ncreate_react_agent\\nand to view an outline of the corresponding code.\\nIt allows you to explore the infrastructure of the agent as defined by the presence of:'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/overview/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='tools: A list of tools (functions, APIs, or other callable objects) that the agent can use to perform tasks.\\npre_model_hook: A function that is called before the model is invoked. It can be used to condense messages or perform other preprocessing tasks.\\npost_model_hook: A function that is called after the model is invoked. It can be used to implement guardrails, human-in-the-loop flows, or other postprocessing tasks.\\nresponse_format: A data structure used to constrain the type of the final output, e.g., a pydantic BaseModel.\\n\\n\\n\\n\\nFeatures\\n tools\\n pre_model_hook\\n post_model_hook\\n response_format\\n\\n\\n\\nGraph\\n\\n\\n\\nThe following code snippet shows how to create the above agent (and underlying graph) with\\ncreate_react_agent:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Guides\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Run an agent\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/overview/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/run_agents/', 'title': 'Run an agent', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='Run an agent\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\nOur new LangChain Academy Course Deep Research with LangGraph is now live! Enroll for free.\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Run an agent\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Run an agent'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/run_agents/', 'title': 'Run an agent', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='Agent development\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Basic usage\\n    \\n\\n\\n\\n\\n\\n      Inputs and outputs\\n    \\n\\n\\n\\n\\n\\n      Input format\\n    \\n\\n\\n\\n\\n\\n      Output format\\n    \\n\\n\\n\\n\\n\\n      Streaming output\\n    \\n\\n\\n\\n\\n\\n      Max iterations\\n    \\n\\n\\n\\n\\n\\n      Additional Resources\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph APIs\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph APIs\\n          \\n\\n\\n\\n\\n    Graph API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runtime\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Core capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Core capabilities\\n          \\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Durable execution\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tracing'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/run_agents/', 'title': 'Run an agent', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tracing\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Additional resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Basic usage\\n    \\n\\n\\n\\n\\n\\n      Inputs and outputs\\n    \\n\\n\\n\\n\\n\\n      Input format\\n    \\n\\n\\n\\n\\n\\n      Output format\\n    \\n\\n\\n\\n\\n\\n      Streaming output\\n    \\n\\n\\n\\n\\n\\n      Max iterations\\n    \\n\\n\\n\\n\\n\\n      Additional Resources\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nagent\\n\\n\\n\\n\\nRunning agents¶\\nAgents support both synchronous and asynchronous execution using either .invoke() / await .ainvoke() for full responses, or .stream() / .astream() for incremental streaming output. This section explains how to provide input, interpret output, enable streaming, and control execution limits.\\nBasic usage¶\\nAgents can be executed in two primary modes:\\n\\nSynchronous using .invoke() or .stream()\\nAsynchronous using await .ainvoke() or async for with .astream()\\n\\nSync invocationAsync invocation'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/run_agents/', 'title': 'Run an agent', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='Sync invocationAsync invocation\\n\\n\\nfrom langgraph.prebuilt import create_react_agent\\n\\nagent = create_react_agent(...)\\n\\nresponse = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]})\\n\\n\\n\\nfrom langgraph.prebuilt import create_react_agent\\n\\nagent = create_react_agent(...)\\nresponse = await agent.ainvoke({\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]})\\n\\n\\n\\n\\nInputs and outputs¶\\nAgents use a language model that expects a list of messages as an input. Therefore, agent inputs and outputs are stored as a list of messages under the messages key in the agent state.\\nInput format¶\\nAgent input must be a dictionary with a messages key. Supported formats are:\\n\\n\\n\\nFormat\\nExample\\n\\n\\n\\n\\nString\\n{\"messages\": \"Hello\"} — Interpreted as a HumanMessage\\n\\n\\nMessage dictionary\\n{\"messages\": {\"role\": \"user\", \"content\": \"Hello\"}}\\n\\n\\nList of messages\\n{\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]}'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/run_agents/', 'title': 'Run an agent', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='List of messages\\n{\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]}\\n\\n\\nWith custom state\\n{\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}], \"user_name\": \"Alice\"} — If using a custom state_schema\\n\\n\\n\\nMessages are automatically converted into LangChain\\'s internal message format. You can read\\nmore about LangChain messages in the LangChain documentation.\\n\\nUsing custom agent state\\nYou can provide additional fields defined in your agent\\'s state schema directly in the input dictionary. This allows dynamic behavior based on runtime data or prior tool outputs.\\nSee the context guide for full details.\\n\\n\\nNote\\nA string input for messages is converted to a HumanMessage. This behavior differs from the prompt parameter in create_react_agent, which is interpreted as a SystemMessage when passed as a string.\\n\\nOutput format¶\\nAgent output is a dictionary containing:'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/run_agents/', 'title': 'Run an agent', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='Output format¶\\nAgent output is a dictionary containing:\\n\\nmessages: A list of all messages exchanged during execution (user input, assistant replies, tool invocations).\\nOptionally, structured_response if structured output is configured.\\nIf using a custom state_schema, additional keys corresponding to your defined fields may also be present in the output. These can hold updated state values from tool execution or prompt logic.\\n\\nSee the context guide for more details on working with custom state schemas and accessing context.\\nStreaming output¶\\nAgents support streaming responses for more responsive applications. This includes:\\n\\nProgress updates after each step\\nLLM tokens as they\\'re generated\\nCustom tool messages during execution\\n\\nStreaming is available in both sync and async modes:\\nSync streamingAsync streaming\\n\\n\\nfor chunk in agent.stream(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\\n    stream_mode=\"updates\"\\n):\\n    print(chunk)'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/run_agents/', 'title': 'Run an agent', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='async for chunk in agent.astream(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\\n    stream_mode=\"updates\"\\n):\\n    print(chunk)\\n\\n\\n\\n\\n\\nTip\\nFor full details, see the streaming guide.\\n\\nMax iterations¶\\nTo control agent execution and avoid infinite loops, set a recursion limit. This defines the maximum number of steps the agent can take before raising a GraphRecursionError. You can configure recursion_limit at runtime or when defining agent via .with_config():\\nRuntime.with_config()\\n\\n\\nfrom langgraph.errors import GraphRecursionError\\nfrom langgraph.prebuilt import create_react_agent\\n\\nmax_iterations = 3\\nrecursion_limit = 2 * max_iterations + 1\\nagent = create_react_agent(\\n    model=\"anthropic:claude-3-5-haiku-latest\",\\n    tools=[get_weather]\\n)'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/run_agents/', 'title': 'Run an agent', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='try:\\n    response = agent.invoke(\\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what\\'s the weather in sf\"}]},\\n        {\"recursion_limit\": recursion_limit},\\n    )\\nexcept GraphRecursionError:\\n    print(\"Agent stopped due to max iterations.\")\\n\\n\\n\\nfrom langgraph.errors import GraphRecursionError\\nfrom langgraph.prebuilt import create_react_agent\\n\\nmax_iterations = 3\\nrecursion_limit = 2 * max_iterations + 1\\nagent = create_react_agent(\\n    model=\"anthropic:claude-3-5-haiku-latest\",\\n    tools=[get_weather]\\n)\\nagent_with_recursion_limit = agent.with_config(recursion_limit=recursion_limit)\\n\\ntry:\\n    response = agent_with_recursion_limit.invoke(\\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what\\'s the weather in sf\"}]},\\n    )\\nexcept GraphRecursionError:\\n    print(\"Agent stopped due to max iterations.\")\\n\\n\\n\\n\\nAdditional Resources¶\\n\\nAsync programming in LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Overview'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/run_agents/', 'title': 'Run an agent', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='Previous\\n              \\n\\n                Overview\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Overview\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='Overview\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\nOur new LangChain Academy Course Deep Research with LangGraph is now live! Enroll for free.\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Overview\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Run an agent'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph APIs\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph APIs\\n          \\n\\n\\n\\n\\n    Graph API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runtime\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Core capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Core capabilities\\n          \\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Durable execution\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n            Human-in-the-loop\\n          \\n\\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Key capabilities\\n    \\n\\n\\n\\n\\n\\n      Patterns\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n    Add human intervention\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tracing\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content=\"Tracing\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Additional resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Key capabilities\\n    \\n\\n\\n\\n\\n\\n      Patterns\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nhil\\nhuman-in-the-loop\\noverview\\n\\n\\n\\n\\nHuman-in-the-loop¶\\nTo review, edit, and approve tool calls in an agent or workflow, use LangGraph's human-in-the-loop features to enable human intervention at any point in a workflow. This is especially useful in large language model (LLM)-driven applications where model output may require validation, correction, or additional context.\\n\\n\\n\\n\\nTip\\nFor information on how to use human-in-the-loop, see Enable human intervention and Human-in-the-loop using Server API.\\n\\nKey capabilities¶\"),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content=\"Key capabilities¶\\n\\n\\nPersistent execution state: Interrupts use LangGraph's persistence layer, which saves the graph state, to indefinitely pause graph execution until you resume. This is possible because LangGraph checkpoints the graph state after each step, which allows the system to persist execution context and later resume the workflow, continuing from where it left off. This supports asynchronous human review or input without time constraints.\\nThere are two ways to pause a graph:\\n\\nDynamic interrupts: Use interrupt to pause a graph from inside a specific node, based on the current state of the graph.\\nStatic interrupts: Use interrupt_before and interrupt_after to pause the graph at pre-defined points, either before or after a node executes.\\n\\n\\n\\nAn example graph consisting of 3 sequential steps with a breakpoint before step_3.\"),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='An example graph consisting of 3 sequential steps with a breakpoint before step_3.  \\n\\n\\nFlexible integration points: Human-in-the-loop logic can be introduced at any point in the workflow. This allows targeted human involvement, such as approving API calls, correcting outputs, or guiding conversations.\\n\\n\\nPatterns¶\\nThere are four typical design patterns that you can implement using interrupt and Command:'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content=\"Approve or reject: Pause the graph before a critical step, such as an API call, to review and approve the action. If the action is rejected, you can prevent the graph from executing the step, and potentially take an alternative action. This pattern often involves routing the graph based on the human's input.\\nEdit graph state: Pause the graph to review and edit the graph state. This is useful for correcting mistakes or updating the state with additional information. This pattern often involves updating the state with the human's input.\\nReview tool calls: Pause the graph to review and edit tool calls requested by the LLM before tool execution.\\nValidate human input: Pause the graph to validate human input before proceeding with the next step.\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Call tools\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Add human intervention\"),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='Next\\n              \\n\\n                Add human intervention\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list = [doc for sublist in docs for doc in sublist] # nested loop\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap =100)\n",
    "\n",
    "doc_splits = text_splitter.split_documents(doc_list)\n",
    "doc_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ed9f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## vector\n",
    "vector_store = FAISS.from_documents(\n",
    "    documents = doc_splits,\n",
    "    embedding = hugging_embedding\n",
    ")\n",
    "\n",
    "## retriever\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38547b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='796685d4-f320-4765-afdc-54872e15b606', metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/overview/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content=\"High-level building blocks¶\\nLangGraph comes with a set of prebuilt components that implement common agent behaviors and workflows. These abstractions are built on top of the LangGraph framework, offering a faster path to production while remaining flexible for advanced customization.\\nUsing LangGraph for agent development allows you to focus on your application's logic and behavior, instead of building and maintaining the supporting infrastructure for state, memory, and human feedback.\\nPackage ecosystem¶\\nThe high-level components are organized into several packages, each with a specific focus.\\n\\n\\n\\nPackage\\nDescription\\nInstallation\\n\\n\\n\\n\\nlanggraph-prebuilt (part of langgraph)\\nPrebuilt components to create agents\\npip install -U langgraph langchain\\n\\n\\nlanggraph-supervisor\\nTools for building supervisor agents\\npip install -U langgraph-supervisor\\n\\n\\nlanggraph-swarm\\nTools for building a swarm multi-agent system\\npip install -U langgraph-swarm\"),\n",
       " Document(id='6b047888-1553-40fd-9a6b-4c67eb000291', metadata={'source': 'https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content=\"Key capabilities¶\\n\\n\\nPersistent execution state: Interrupts use LangGraph's persistence layer, which saves the graph state, to indefinitely pause graph execution until you resume. This is possible because LangGraph checkpoints the graph state after each step, which allows the system to persist execution context and later resume the workflow, continuing from where it left off. This supports asynchronous human review or input without time constraints.\\nThere are two ways to pause a graph:\\n\\nDynamic interrupts: Use interrupt to pause a graph from inside a specific node, based on the current state of the graph.\\nStatic interrupts: Use interrupt_before and interrupt_after to pause the graph at pre-defined points, either before or after a node executes.\\n\\n\\n\\nAn example graph consisting of 3 sequential steps with a breakpoint before step_3.\"),\n",
       " Document(id='ec90d805-f5d0-4d03-b05a-17d7d24cc34c', metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/run_agents/', 'title': 'Run an agent', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='Run an agent\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\nOur new LangChain Academy Course Deep Research with LangGraph is now live! Enroll for free.\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Run an agent\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Run an agent'),\n",
       " Document(id='b92fe1d9-3195-4e5a-ac2b-836f9bf3b154', metadata={'source': 'https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='Overview\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\nOur new LangChain Academy Course Deep Research with LangGraph is now live! Enroll for free.\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Overview\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Run an agent')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What is langgraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d45b6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retriever to retriever tools\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool_langgraph = create_retriever_tool(\n",
    "    retriever=retriever,\n",
    "    name = \"retriever_vector_db_blog\",\n",
    "    description=\"Search and run information about Langgraph\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b5c10d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='retriever_vector_db_blog', description='Search and run information about Langgraph', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x00000248A21CD3A0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002489EC53B30>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x00000248A21CD800>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002489EC53B30>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool_langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83a704a",
   "metadata": {},
   "source": [
    "### Another vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3d20a81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_urls = [\n",
    "    \"https://python.langchain.com/docs/tutorials/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in langchain_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a65523ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/', 'title': 'Tutorials | 🦜️🔗 LangChain', 'description': 'New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nTutorials | 🦜️🔗 LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentOur new LangChain Academy Course Deep Research with LangGraph is now live! Enroll for free.IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1💬SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain\\'s stateHow to construct filters for query analysisHow to configure runtime chain internalsHow to deal with high-cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with LangChainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem🦜🛠️ LangSmith🦜🕸️ LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyTutorialsOn this pageTutorials\\nNew to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.\\nGet started\\u200b\\nFamiliarize yourself with LangChain\\'s open-source components by building simple applications.\\nIf you\\'re looking to get started with chat models, vector stores,\\nor other LangChain components from a specific provider, check out our supported integrations.\\n\\nChat models and prompts: Build a simple LLM application with prompt templates and chat models.\\nSemantic search: Build a semantic search engine over a PDF with document loaders, embedding models, and vector stores.\\nClassification: Classify text into categories or labels using chat models with structured outputs.\\nExtraction: Extract structured data from text and other unstructured media using chat models and few-shot examples.\\n\\nRefer to the how-to guides for more detail on using all LangChain components.\\nOrchestration\\u200b\\nGet started using LangGraph to assemble LangChain components into full-featured applications.\\n\\nChatbots: Build a chatbot that incorporates memory.\\nAgents: Build an agent that interacts with external tools.\\nRetrieval Augmented Generation (RAG) Part 1: Build an application that uses your own documents to inform its responses.\\nRetrieval Augmented Generation (RAG) Part 2: Build a RAG application that incorporates a memory of its user interactions and multi-step retrieval.\\nQuestion-Answering with SQL: Build a question-answering system that executes SQL queries to inform its responses.\\nSummarization: Generate summaries of (potentially long) texts.\\nQuestion-Answering with Graph Databases: Build a question-answering system that queries a graph database to inform its responses.\\n\\nLangSmith\\u200b\\nLangSmith allows you to closely trace, monitor and evaluate your LLM application.\\nIt seamlessly integrates with LangChain, and you can use it to inspect and debug individual steps of your chains as you build.\\nLangSmith documentation is hosted on a separate site.\\nYou can peruse LangSmith tutorials here.\\nEvaluation\\u200b\\nLangSmith helps you evaluate the performance of your LLM applications. The tutorial below is a great way to get started:\\n\\nEvaluate your LLM application\\nEdit this pagePreviousIntroductionNextBuild a Question Answering application over a Graph DatabaseGet startedOrchestrationLangSmithEvaluationCommunityLangChain ForumTwitterSlackGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright © 2025 LangChain, Inc.\\n\\n')]]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "50a21350",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 100\n",
    ")\n",
    "\n",
    "doc_split = text_splitter.split_documents(docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "af6b37a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/', 'title': 'Tutorials | 🦜️🔗 LangChain', 'description': 'New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nTutorials | 🦜️🔗 LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentOur new LangChain Academy Course Deep Research with LangGraph is now live! Enroll for free.IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1💬SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain\\'s stateHow to construct filters for query analysisHow to configure runtime chain internalsHow to deal with high-cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with LangChainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem🦜🛠️ LangSmith🦜🕸️ LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyTutorialsOn this pageTutorials\\nNew to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.\\nGet started\\u200b\\nFamiliarize yourself with LangChain\\'s open-source components by building simple applications.\\nIf you\\'re looking to get started with chat models, vector stores,\\nor other LangChain components from a specific provider, check out our supported integrations.\\n\\nChat models and prompts: Build a simple LLM application with prompt templates and chat models.\\nSemantic search: Build a semantic search engine over a PDF with document loaders, embedding models, and vector stores.\\nClassification: Classify text into categories or labels using chat models with structured outputs.\\nExtraction: Extract structured data from text and other unstructured media using chat models and few-shot examples.\\n\\nRefer to the how-to guides for more detail on using all LangChain components.\\nOrchestration\\u200b\\nGet started using LangGraph to assemble LangChain components into full-featured applications.\\n\\nChatbots: Build a chatbot that incorporates memory.\\nAgents: Build an agent that interacts with external tools.\\nRetrieval Augmented Generation (RAG) Part 1: Build an application that uses your own documents to inform its responses.\\nRetrieval Augmented Generation (RAG) Part 2: Build a RAG application that incorporates a memory of its user interactions and multi-step retrieval.\\nQuestion-Answering with SQL: Build a question-answering system that executes SQL queries to inform its responses.\\nSummarization: Generate summaries of (potentially long) texts.\\nQuestion-Answering with Graph Databases: Build a question-answering system that queries a graph database to inform its responses.\\n\\nLangSmith\\u200b\\nLangSmith allows you to closely trace, monitor and evaluate your LLM application.\\nIt seamlessly integrates with LangChain, and you can use it to inspect and debug individual steps of your chains as you build.\\nLangSmith documentation is hosted on a separate site.\\nYou can peruse LangSmith tutorials here.\\nEvaluation\\u200b\\nLangSmith helps you evaluate the performance of your LLM applications. The tutorial below is a great way to get started:\\n\\nEvaluate your LLM application\\nEdit this pagePreviousIntroductionNextBuild a Question Answering application over a Graph DatabaseGet startedOrchestrationLangSmithEvaluationCommunityLangChain ForumTwitterSlackGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright © 2025 LangChain, Inc.\\n\\n')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6bac9e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_langchain = FAISS.from_documents(\n",
    "    documents=docs_list,\n",
    "    embedding=hugging_embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ac57942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_langchain = vector_store_langchain.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a71872d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make tool\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool_langchain = create_retriever_tool(\n",
    "    retriever_langchain,\n",
    "    \"retriever_vector_langchain_blog\",\n",
    "    \"serach and run information about langchain\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "70eb283a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='retriever_vector_langchain_blog', description='serach and run information about langchain', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x00000248A21CD3A0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000248E78F92B0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x00000248A21CD800>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000248E78F92B0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool_langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4edd3c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_tool_langgraph, retriever_tool_langchain]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c5af8d",
   "metadata": {},
   "source": [
    "### Langgraph Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "80b4ec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence, Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "28a65b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages : Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c05d65bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model = \"qwen/qwen3-32b\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "90edbe82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user sent \"Hi\". That\\'s pretty casual. I should respond in a friendly and welcoming way. Maybe ask how they\\'re doing or if there\\'s something I can help with. Keep it open-ended so they can decide what to talk about next. Let me make sure the tone is warm and approachable.\\n</think>\\n\\nHello! How can I assist you today? 😊', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 9, 'total_tokens': 90, 'completion_time': 0.258467287, 'prompt_time': 0.007492524, 'queue_time': 0.043406216, 'total_time': 0.265959811}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--4b59f856-3a5b-4fc9-9966-cbedb2811953-0', usage_metadata={'input_tokens': 9, 'output_tokens': 81, 'total_tokens': 90})"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a8977981",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nodes\n",
    "def agent(state : AgentState):\n",
    "    \"\"\"\n",
    "    Invokes the agent model to generate a response based on the current state.\n",
    "    Given the question, it will decide to retrieve using the retriever tool, or simply end.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): The current state\n",
    "        \n",
    "    Returns:\n",
    "        dict: The updated state with the agent response appended to messages\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"____CALL AGENT____\")\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    model_with_tools = llm.bind_tools(tools)\n",
    "    \n",
    "    response = model_with_tools.invoke(messages)\n",
    "    \n",
    "    return {\"messages\" : [response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "55832962",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Edges\n",
    "def grade_documents(state : AgentState) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Determine whether the retrieved documents are relevant to the question.\n",
    "    \n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "        \n",
    "    Returns:\n",
    "        str : A decision for whether the documents are relevant or not \n",
    "    \"\"\"\n",
    "    \n",
    "    class grade(BaseModel):\n",
    "        \"\"\"Binary  Score for relevance check\"\"\"\n",
    "        \n",
    "        binary_score : str = Field(description=\"Relevance score 'yes' or 'no' \")\n",
    "        \n",
    "    llm_with_structure = llm.with_structured_output(grade)\n",
    "    \n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "            You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
    "            Here is the retrieved document : \\n\\n {context} \\n\\n\n",
    "            Here is the question: {question} \\n\n",
    "            If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "            Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\n",
    "        \"\"\",\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm_with_structure\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    last_messages = messages[-1]\n",
    "    \n",
    "    question = messages[0].content\n",
    "    docs = last_messages.content\n",
    "    \n",
    "    scored_result = chain.invoke({\"question\" : question, \"context\" : docs})\n",
    "    \n",
    "    score = scored_result.binary_score\n",
    "    \n",
    "    if score == 'yes':\n",
    "        print(\"_____DECISION: DOCS RELEVANT_____\")\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        print(\"_____DECISION: DOCS NOT RELEVANT_____\")\n",
    "        print(score)\n",
    "        return \"rewrite\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8661c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state : AgentState):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): The current state\n",
    "        \n",
    "    Returns:\n",
    "        dict : The updated message\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"____GENERATE____\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    last_question = messages[-1]\n",
    "    \n",
    "    docs = last_question.content\n",
    "    \n",
    "    # Prompt\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "    \n",
    "    # def format_docs(docs):\n",
    "    #     return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "    # chain\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "    \n",
    "    response = rag_chain.invoke({\"context\" : docs, \"question\" : question})\n",
    "    \n",
    "    return {'messages' : [response]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0e55e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(state : AgentState):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): The current state\n",
    "        \n",
    "    Returns: \n",
    "        dict: The updated state with re-phrased question\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"___TRANSFORM QUERY___\")\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    \n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\"\\n\n",
    "                Look at the input and try to reason about the underlying semantic intent / meaning. \\n\n",
    "                Here is the initial question:\n",
    "                \\n-------\\n\n",
    "                {question}\n",
    "                \\n-------\\n\n",
    "                Formulate an improved question: \n",
    "            \"\"\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    response = llm.invoke(msg)\n",
    "    \n",
    "    return {\"messages\" : [response]}\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5e7c688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.prebuilt import ToolNode, tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "51b5d6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x248e7513ad0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## State graph\n",
    "\n",
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "# Add node\n",
    "graph_builder.add_node(\"agent\", agent)\n",
    "graph_builder.add_node(\"retrieve\", ToolNode(tools))\n",
    "graph_builder.add_node(\"rewrite\", rewrite)\n",
    "graph_builder.add_node(\"generate\", generate)\n",
    "\n",
    "# add edge\n",
    "graph_builder.add_edge(START, \"agent\")\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    tools_condition,\n",
    "    {\n",
    "        \"tools\" : \"retrieve\",\n",
    "        END : END\n",
    "    }\n",
    ")\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    grade_documents\n",
    ")\n",
    "\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "graph_builder.add_edge(\"rewrite\", \"agent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "54aeb91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f2ca5ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1157663e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____CALL AGENT____\n",
      "_____DECISION: DOCS RELEVANT_____\n",
      "____GENERATE____\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is langchain?', additional_kwargs={}, response_metadata={}, id='31aae31e-48bc-4263-aa4a-ce04627fe181'),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking \"What is langchain?\" I need to figure out which tool to use here. Let me check the available functions. There\\'s one called retriever_vector_db_blog for Langgraph and another called retriever_vector_langchain_blog for Langchain. Since the question is about Langchain, the second function seems appropriate. I should call that function with a query parameter that\\'s a general question about Langchain. The query should probably be \"What is Langchain?\" to get the most relevant information. I need to make sure the arguments are correctly formatted as JSON within the tool_call tags. Let me structure the response accordingly.\\n', 'tool_calls': [{'id': 'r4gsfdtw7', 'function': {'arguments': '{\"query\":\"What is Langchain?\"}', 'name': 'retriever_vector_langchain_blog'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 163, 'prompt_tokens': 243, 'total_tokens': 406, 'completion_time': 0.310078491, 'prompt_time': 0.109873931, 'queue_time': 0.046197179, 'total_time': 0.419952422}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--3e8723ce-52e7-4167-83a7-36aafc78c17b-0', tool_calls=[{'name': 'retriever_vector_langchain_blog', 'args': {'query': 'What is Langchain?'}, 'id': 'r4gsfdtw7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 243, 'output_tokens': 163, 'total_tokens': 406}),\n",
       "  ToolMessage(content='\\n\\n\\n\\n\\nTutorials | 🦜️🔗 LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentOur new LangChain Academy Course Deep Research with LangGraph is now live! Enroll for free.IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1💬SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain\\'s stateHow to construct filters for query analysisHow to configure runtime chain internalsHow to deal with high-cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with LangChainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem🦜🛠️ LangSmith🦜🕸️ LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyTutorialsOn this pageTutorials\\nNew to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.\\nGet started\\u200b\\nFamiliarize yourself with LangChain\\'s open-source components by building simple applications.\\nIf you\\'re looking to get started with chat models, vector stores,\\nor other LangChain components from a specific provider, check out our supported integrations.\\n\\nChat models and prompts: Build a simple LLM application with prompt templates and chat models.\\nSemantic search: Build a semantic search engine over a PDF with document loaders, embedding models, and vector stores.\\nClassification: Classify text into categories or labels using chat models with structured outputs.\\nExtraction: Extract structured data from text and other unstructured media using chat models and few-shot examples.\\n\\nRefer to the how-to guides for more detail on using all LangChain components.\\nOrchestration\\u200b\\nGet started using LangGraph to assemble LangChain components into full-featured applications.\\n\\nChatbots: Build a chatbot that incorporates memory.\\nAgents: Build an agent that interacts with external tools.\\nRetrieval Augmented Generation (RAG) Part 1: Build an application that uses your own documents to inform its responses.\\nRetrieval Augmented Generation (RAG) Part 2: Build a RAG application that incorporates a memory of its user interactions and multi-step retrieval.\\nQuestion-Answering with SQL: Build a question-answering system that executes SQL queries to inform its responses.\\nSummarization: Generate summaries of (potentially long) texts.\\nQuestion-Answering with Graph Databases: Build a question-answering system that queries a graph database to inform its responses.\\n\\nLangSmith\\u200b\\nLangSmith allows you to closely trace, monitor and evaluate your LLM application.\\nIt seamlessly integrates with LangChain, and you can use it to inspect and debug individual steps of your chains as you build.\\nLangSmith documentation is hosted on a separate site.\\nYou can peruse LangSmith tutorials here.\\nEvaluation\\u200b\\nLangSmith helps you evaluate the performance of your LLM applications. The tutorial below is a great way to get started:\\n\\nEvaluate your LLM application\\nEdit this pagePreviousIntroductionNextBuild a Question Answering application over a Graph DatabaseGet startedOrchestrationLangSmithEvaluationCommunityLangChain ForumTwitterSlackGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright © 2025 LangChain, Inc.\\n\\n', name='retriever_vector_langchain_blog', id='849a239a-0ada-422b-affe-c67caca1c9d9', tool_call_id='r4gsfdtw7'),\n",
       "  HumanMessage(content='<think>\\nOkay, the user is asking \"What is langchain?\" Let me look through the provided context to find relevant information.\\n\\nThe context includes a lot of tutorials and how-to guides. From the sections mentioned, LangChain seems to be a framework for building applications with large language models (LLMs). It mentions components like chat models, vector stores, and tools for tasks like semantic search, classification, and extraction. There\\'s also mention of LangGraph for orchestration and LangSmith for monitoring. \\n\\nPutting this together, LangChain is a framework that helps in building LLM-powered apps by providing tools for integration, orchestration, and evaluation. I should mention its key features like connecting models, using retrieval-augmented generation (RAG), and supporting various components like chatbots and agents. Keep it concise, three sentences max.\\n</think>\\n\\nLangChain is a framework for developing applications powered by large language models (LLLMs), offering tools to integrate models, data, and tools for tasks like chatbots, retrieval-augmented generation (RAG), and agents. It provides components for orchestration, memory, and evaluation, enabling structured workflows with LLMs. Built-in support for vector stores, prompts, and external APIs simplifies building and deploying AI-driven applications.', additional_kwargs={}, response_metadata={}, id='ac25d4e2-c54f-4231-b7c4-97f726785932')]}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\" : \"What is langchain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "61fd06d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____CALL AGENT____\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is Machine Learning?', additional_kwargs={}, response_metadata={}, id='b7e49448-6978-4498-9fe2-ac1b3e9f3cfa'),\n",
       "  AIMessage(content=\"The provided tools are designed to search for information related to Langgraph and Langchain. Since your question is about Machine Learning, which is a broader field, I can't use the available tools to retrieve a specific answer. However, I can tell you that Machine Learning is a subset of artificial intelligence that involves building systems that can learn from data, identify patterns, and make decisions with minimal human intervention. It encompasses various algorithms and statistical models that enable computers to improve their performance on a task through experience.\", additional_kwargs={'reasoning_content': 'Okay, the user is asking \"What is Machine Learning?\" Let me think about how to approach this. First, I need to determine if the provided tools can help answer this. The available functions are for searching information about Langgraph and langchain. The user\\'s question is a general one about Machine Learning, not specifically related to those tools. Since neither of the functions is designed to retrieve general Machine Learning information, I should conclude that none of the provided tools are suitable for this query. Therefore, I\\'ll inform the user that I can\\'t use the available tools to answer their question and proceed to provide a standard definition of Machine Learning.\\n'}, response_metadata={'token_usage': {'completion_tokens': 233, 'prompt_tokens': 243, 'total_tokens': 476, 'completion_time': 0.529292912, 'prompt_time': 0.089590326, 'queue_time': 0.046656504, 'total_time': 0.618883238}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--05ffdf1c-4cdd-4d3d-b7d9-9c5a92c49348-0', usage_metadata={'input_tokens': 243, 'output_tokens': 233, 'total_tokens': 476})]}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\" : \"What is Machine Learning?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e92a8295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____CALL AGENT____\n",
      "_____DECISION: DOCS RELEVANT_____\n",
      "____GENERATE____\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is langgraph?', additional_kwargs={}, response_metadata={}, id='c0e2e527-7a1e-40af-ac8f-6e7c744703e0'),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking \"What is langgraph?\" Let me see. First, I need to determine which tool to use here. The available functions are retriever_vector_db_blog for Langgraph and retriever_vector_langchain_blog for langchain. Since the user specifically mentioned \"langgraph,\" I should use the first function. The parameters require a \"query\" string. The question is straightforward, so the query should be \"What is langgraph?\" I\\'ll call the retriever_vector_db_blog function with that query to get the necessary information.\\n', 'tool_calls': [{'id': 'h0y4axb6z', 'function': {'arguments': '{\"query\":\"What is langgraph?\"}', 'name': 'retriever_vector_db_blog'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 143, 'prompt_tokens': 243, 'total_tokens': 386, 'completion_time': 0.352143112, 'prompt_time': 0.023174719, 'queue_time': 0.046237611, 'total_time': 0.375317831}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b8974300-015c-4568-85a4-adfed6860750-0', tool_calls=[{'name': 'retriever_vector_db_blog', 'args': {'query': 'What is langgraph?'}, 'id': 'h0y4axb6z', 'type': 'tool_call'}], usage_metadata={'input_tokens': 243, 'output_tokens': 143, 'total_tokens': 386}),\n",
       "  ToolMessage(content=\"High-level building blocks¶\\nLangGraph comes with a set of prebuilt components that implement common agent behaviors and workflows. These abstractions are built on top of the LangGraph framework, offering a faster path to production while remaining flexible for advanced customization.\\nUsing LangGraph for agent development allows you to focus on your application's logic and behavior, instead of building and maintaining the supporting infrastructure for state, memory, and human feedback.\\nPackage ecosystem¶\\nThe high-level components are organized into several packages, each with a specific focus.\\n\\n\\n\\nPackage\\nDescription\\nInstallation\\n\\n\\n\\n\\nlanggraph-prebuilt (part of langgraph)\\nPrebuilt components to create agents\\npip install -U langgraph langchain\\n\\n\\nlanggraph-supervisor\\nTools for building supervisor agents\\npip install -U langgraph-supervisor\\n\\n\\nlanggraph-swarm\\nTools for building a swarm multi-agent system\\npip install -U langgraph-swarm\\n\\nKey capabilities¶\\n\\n\\nPersistent execution state: Interrupts use LangGraph's persistence layer, which saves the graph state, to indefinitely pause graph execution until you resume. This is possible because LangGraph checkpoints the graph state after each step, which allows the system to persist execution context and later resume the workflow, continuing from where it left off. This supports asynchronous human review or input without time constraints.\\nThere are two ways to pause a graph:\\n\\nDynamic interrupts: Use interrupt to pause a graph from inside a specific node, based on the current state of the graph.\\nStatic interrupts: Use interrupt_before and interrupt_after to pause the graph at pre-defined points, either before or after a node executes.\\n\\n\\n\\nAn example graph consisting of 3 sequential steps with a breakpoint before step_3.\\n\\nRun an agent\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\nOur new LangChain Academy Course Deep Research with LangGraph is now live! Enroll for free.\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Run an agent\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Run an agent\\n\\nOverview\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\nOur new LangChain Academy Course Deep Research with LangGraph is now live! Enroll for free.\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Overview\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Run an agent\", name='retriever_vector_db_blog', id='0d552d27-2102-4727-9126-99f9acf5b839', tool_call_id='h0y4axb6z'),\n",
       "  HumanMessage(content=\"<think>\\nOkay, I need to figure out what LangGraph is based on the provided context. Let me start by reading through the context carefully.\\n\\nThe context mentions that LangGraph has high-level building blocks with prebuilt components for common agent behaviors and workflows. It's built on the LangGraph framework, allowing faster production while being flexible for customization. The key points are about agent development, focusing on application logic instead of infrastructure like state and memory. There are packages like langgraph-prebuilt, langgraph-supervisor, and langgraph-swarm, each with specific roles. Also, it talks about persistent execution state with interrupts, checkpoints, and asynchronous human input.\\n\\nSo, putting this together, LangGraph seems to be a framework for building agent systems. It provides tools to handle state, memory, and human feedback, which allows developers to focus on the application's logic. The packages mentioned are part of its ecosystem, offering different functionalities like supervisors and swarms. The persistent execution state feature allows pausing and resuming workflows, which is useful for agents needing human intervention.\\n\\nI need to make sure I don't miss any key points. The answer should mention it's a framework for agent development, the prebuilt components, the packages, and maybe the persistent execution state. Since the user wants a concise answer in three sentences max, I have to be concise. Let me check again: the main purpose, key features (prebuilt components, packages), and a key capability like persistent state. That should cover it without going over the limit.\\n</think>\\n\\nLangGraph is a framework for building agent systems, offering prebuilt components to streamline workflows and focus on application logic rather than infrastructure. It includes packages like `langgraph-prebuilt` for agents, `langgraph-supervisor` for oversight, and `langgraph-swarm` for multi-agent systems. Key features include persistent execution state, enabling checkpoints and resumable workflows with human feedback.\", additional_kwargs={}, response_metadata={}, id='382208bc-ac47-4ca2-8c1c-71ed99c9f0a7')]}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\" : \"What is langgraph?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b587fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
